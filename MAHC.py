# -*- coding: utf-8 -*-
"""
# Agente de Sa√∫de Mental e Bem-Estar - Sistema Multi-Agente Finalizado com Mentor

Este c√≥digo Python implementa um sistema de agentes conversacionais para auxiliar
pessoas com problemas emocionais e promover exerc√≠cios, seguindo um padr√£o
inspirado no Agent Development Kit (ADK) do Google. Ele separa as responsabilidades
em m√∫ltiplos Agentes especializados, incluindo um novo Agente Mentor, Ferramentas
(Tools) e um Orquestrador.

## Configura√ß√£o no Google Colab

Para executar este c√≥digo no Google Colab, siga os passos abaixo:

1.  **Instalar a biblioteca google-generativeai:**
    Execute a seguinte linha em uma c√©lula do seu notebook Colab:
    ```bash
    !pip install google-generativeai
    ```

2.  **Obter sua Chave de API do Google AI Studio:**
    Se voc√™ ainda n√£o tem uma chave de API, acesse o Google AI Studio
    (https://aistudio.google.com/) e crie uma nova chave de API.

3.  **Configurar a Chave de API no Colab (Recomendado: Secrets Manager):**
    A forma mais segura de configurar sua chave de API no Google Colab √© usando o
    Secrets Manager:
    * No menu √† esquerda do Colab, clique no √≠cone de chave (`üîë`).
    * Clique em `Gerenciar secrets`.
    * Clique em `+ Novo secret`.
    * No campo `Nome`, inscreva um nome para o seu secret (por exemplo, `GOOGLE_API_KEY`).
    * No campo `Valor`, cole o valor da sua chave de API real.
    * Certifique-se de que a op√ß√£o `Notebook access` est√° ativada para este secret.
    * No c√≥digo abaixo, descomente as linhas que carregam a chave usando `userdata.get()`
        e comente a linha `API_KEY = "YOUR_API_KEY"`.
    * Substitua `'YOUR_API_KEY_NAME_IN_SECRETS'` pelo nome que voc√™ deu ao seu secret
        no Secrets Manager.

    Alternativamente (N√ÉO RECOMENDADO para chaves sens√≠veis), voc√™ pode substituir
    a string placeholder `"YOUR_API_KEY"` diretamente no c√≥digo pela sua chave real,
    mas **tenha cuidado para n√£o compartilhar seu notebook com a chave exposta**.

4.  **Executar o C√≥digo:**
    Execute as c√©lulas do c√≥digo no seu notebook Colab. A fun√ß√£o `main()` iniciar√°
    o sistema de agentes e voc√™ poder√° interagir com ele atrav√©s da linha de comando
    no output da c√©lula.

## Estrutura do C√≥digo

O c√≥digo est√° organizado da seguinte forma:

-   **Ferramentas (Tools):** Classes que encapsulam intera√ß√µes com servi√ßos externos,
    como a `GeminiTool` para comunica√ß√£o com o modelo Gemini.
-   **Agentes (Agents):** Classes que herdam de `BaseAgent` e implementam a l√≥gica
    especializada para diferentes dom√≠nulos (Suporte Emocional, Exerc√≠cio, Conhecimento, Mentor).
-   **Orquestrador (Orchestrator):** Gerencia o fluxo da conversa, roteia as entradas
    do usu√°rio para os agentes apropriados e mant√©m o estado (hist√≥rico da conversa,
    perfil do usu√°rio).
-   **main():** Fun√ß√£o principal que configura o ambiente (API, ferramentas, agentes)
    e inicia o Orquestrador.

"""

import os
import datetime
import random # Importa√ß√£o da biblioteca random adicionada
from typing import List, Dict, Any, Optional
# IMPORTANTE: A biblioteca google-generativeai precisa ser instalada no ambiente
# Para Google Colab, execute: !pip install google-generativeai
import google.generativeai as genai

# --- Defini√ß√£o das Ferramentas (Tools) ---
# A classe GeminiTool foi movida para c√° para ser definida antes de ser usada.

class GeminiTool:
    """
    Uma ferramenta para interagir com o modelo Gemini do Google AI Studio.
    Encapsula a l√≥gica de chamada da API.
    """
    def __init__(self, model: genai.GenerativeModel):
        self.model = model

    def generate_text(self, prompt: str) -> str:
        """
        Generates text using the Gemini model.

        Args:
            prompt (str): The text prompt for the model.

        Returns:
            str: The text generated by the model.
        """
        try:
            # Configura√ß√µes de seguran√ßa para garantir respostas apropriadas
            safety_settings = [
                {"category": "HARM_CATEGORY_HARASSMENT", "threshold": "BLOCK_MEDIUM_AND_ABOVE"},
                {"category": "HARM_CATEGORY_HATE_SPEECH", "threshold": "BLOCK_MEDIUM_AND_ABOVE"},
                {"category": "HARM_CATEGORY_SEXUALLY_EXPLICIT", "threshold": "BLOCK_MEDIUM_AND_ABOVE"},
                {"category": "HARM_CATEGORY_DANGEROUS_CONTENT", "threshold": "BLOCK_MEDIUM_AND_ABOVE"},
            ]
            # Gera√ß√£o de conte√∫do com configura√ß√µes de seguran√ßa
            response = self.model.generate_content(prompt, safety_settings=safety_settings)

            # Verifica se houve bloqueios de seguran√ßa
            if hasattr(response, 'prompt_feedback') and response.prompt_feedback.block_reason:
                 print(f"Conte√∫do bloqueado por motivo de seguran√ßa: {response.prompt_feedback.block_reason}")
                 return "Desculpe, n√£o posso responder a isso de acordo com minhas diretrizes de seguran√ßa."
            if hasattr(response, 'candidates') and not response.candidates:
                 print("Resposta bloqueada - nenhum candidato gerado.")
                 return "Desculpe, n√£o consigo gerar uma resposta para isso no momento."


            return response.text.strip()
        except Exception as e:
            print(f"Erro na ferramenta Gemini ao gerar texto: {e}")
            return "Desculpe, n√£o consigo processar sua solicita√ß√£o no momento."


# --- Configura√ß√£o da API do Google AI Studio ---
# √â ALTAMENTE recomendado usar vari√°veis de ambiente ou o Secrets Manager do Colab
# para armazenar sua chave de API de forma segura.
# Exemplo usando vari√°vel de ambiente: os.getenv("GOOGLE_API_KEY")
# Substitua a string placeholder "YOUR_API_KEY" pela sua chave de API real.
API_KEY = "AIzaSyBqkjOJk6RVjZ_3ltr1Nbf19acdcGJZa_c" # SUA CHAVE DE API REAL

# --- Carregar chave usando Secrets Manager do Colab (descomente e configure o Secret) ---
# try:
#     from google.colab import userdata
#     API_KEY = userdata.get('YOUR_API_KEY_NAME_IN_SECRETS') # Substitua pelo nome do seu Secret
#     if API_KEY is None:
#         print("AVISO: Chave de API n√£o encontrada no Secrets Manager.")
#         print("Por favor, configure seu Secret ou substitua 'YOUR_API_KEY' no c√≥digo.")
# except ImportError:
#     print("AVISO: N√£o est√° no ambiente Google Colab ou a biblioteca userdata n√£o est√° dispon√≠vel.")
#     print("Por favor, substitua 'YOUR_API_KEY' no c√≥digo pela sua chave de API real.")


# Vari√°vel global para a ferramenta Gemini (inicializada ap√≥s configura√ß√£o)
gemini_tool: Optional['GeminiTool'] = None
llm_model: Optional[genai.GenerativeModel] = None # Vari√°vel para o modelo LLM

if API_KEY == "YOUR_API_KEY":
    print("AVISO: A chave de API n√£o foi configurada.")
    print("Por favor, substitua 'YOUR_API_KEY' no c√≥digo pela sua chave de API real do Google AI Studio.")
    print("O sistema de agentes n√£o poder√° funcionar corretamente sem uma chave de API v√°lida.")
else:
    try:
        genai.configure(api_key=API_KEY)
        # Use um modelo adequado para conversa√ß√£o. Verifique a documenta√ß√£o do Google AI Studio
        # ou use genai.list_models() para ver os modelos dispon√≠veis e seus supported_methods.
        # 'gemini-1.5-flash-latest' √© uma op√ß√£o recente e geralmente dispon√≠vel.
        llm_model = genai.GenerativeModel('gemini-1.5-flash-latest') # Modelo atualizado para gemini-1.5-flash-latest
        gemini_tool = GeminiTool(llm_model) # Inicializa a ferramenta Gemini
        # Pequeno teste para verificar a conex√£o - descomente se necess√°rio para depura√ß√£o
        # try:
        #     gemini_tool.generate_text("Test connection")
        #     print("Conex√£o com o Google AI Studio bem-sucedida.")
        # except Exception as test_e:
        #     print(f"ERRO: Falha no teste de conex√£o com o Google AI Studio: {test_e}")
        #     gemini_tool = None # Define a ferramenta como None em caso de falha no teste
    except Exception as e:
        print(f"ERRO: Falha ao configurar ou conectar ao Google AI Studio: {e}")
        print("Por favor, verifique sua chave de API e a configura√ß√£o do modelo.")
        gemini_tool = None # Garante que a ferramenta seja None em caso de falha


# --- Defini√ß√£o dos Agentes ---

class BaseAgent:
    """Classe base para todos os agentes."""
    def __init__(self, name: str, version: str, gemini_tool: Optional[GeminiTool]):
        self.name = name
        self.version = version
        self.gemini_tool = gemini_tool

    def process_input(self, user_input: str, conversation_history: List[Dict[str, str]], user_profile: Dict[str, Any]) -> str:
        """
        Processa a entrada do usu√°rio e gera uma resposta.
        Deve ser implementado pelas classes filhas.

        Args:
            user_input (str): A mensagem do usu√°rio.
            conversation_history (List[Dict[str, str]]): Hist√≥rico completo da conversa.
            user_profile (Dict[str, Any]): Perfil do usu√°rio.

        Returns:
            str: A resposta gerada pelo agente.
        """
        raise NotImplementedError("O m√©todo process_input deve ser implementado pelas subclasses.")

    def _build_prompt(self, user_input: str, conversation_history: List[Dict[str, str]], user_profile: Dict[str, Any], agent_instructions: str) -> str:
        """Constr√≥i o prompt completo para o modelo Gemini."""
        context = f"{agent_instructions}\n\n"
        if user_profile:
            context += f"Perfil do Usu√°rio: {user_profile}\n\n"
        context += "Hist√≥rico da Conversa:\n"
        # Inclui apenas uma parte relevante do hist√≥rico para evitar exceder o limite de tokens
        # A l√≥gica de resumo ou sele√ß√£o inteligente de hist√≥rico pode ser adicionada aqui.
        recent_history = conversation_history[-20:] # Exemplo: √∫ltimas 20 intera√ß√µes
        for message in recent_history:
            context += f"{message['sender']}: {message['content']}\n"
        context += f"\nUsu√°rio: {user_input}\nAgente:"
        return context


class EmotionalSupportAgent(BaseAgent):
    """Agente especializado em suporte emocional (ansiedade, depress√£o, raiva, pensamentos intrusivos)."""
    def __init__(self, gemini_tool: Optional[GeminiTool]):
        super().__init__("AgenteSuporteEmocional", "1.0.13", gemini_tool) # Vers√£o atualizada
        self.instructions = """
Voc√™ √© o AgenteSuporteEmocional do BemEstarBot. Seu foco √© fornecer suporte
emp√°tico e baseado em evid√™ncias para usu√°rios que lidam com ansiedade,
depress√£o, raiva e pensamentos intrusivos. Utilize princ√≠pios de TCC e ACT de
forma conversacional.

Seja extremamente emp√°tico, ouvinte ativo e demonstre compreens√£o. Incentive o
usu√°rio a compartilhar seus sentimentos e explore as situa√ß√µes com perguntas
abertas. Ofere√ßa t√©cnicas pr√°ticas e baseadas em estudos para gerenciar emo√ß√µes
dif√≠ceis, sempre com um tom de apoio e sem julgamento.

Lembre-se de que voc√™ √© uma IA e n√£o um terapeuta. Em situa√ß√µes de sofrimento
significativo ou crise, reforce a import√¢ncia de procurar ajuda profissional.

Considere o hist√≥rico da conversa para manter o contexto e personalize suas
respostas com base no que o usu√°rio j√° compartilhou.
"""

    def process_input(self, user_input: str, conversation_history: List[Dict[str, str]], user_profile: Dict[str, Any]) -> str:
        if not self.gemini_tool:
            return "Desculpe, o Agente de Suporte Emocional n√£o est√° dispon√≠vel no momento."

        prompt = self._build_prompt(user_input, conversation_history, user_profile, self.instructions)
        return self.gemini_tool.generate_text(prompt)


class ExerciseAgent(BaseAgent):
    """Agente especializado em promover e recomendar exerc√≠cios f√≠sicos."""
    def __init__(self, gemini_tool: Optional[GeminiTool]):
        super().__init__("AgenteExercicio", "1.0.13", gemini_tool) # Vers√£o atualizada
        self.instructions = """
Voc√™ √© o AgenteExercicio do BemEstarBot. Seu foco √© motivar e guiar os usu√°rios
na pr√°tica de exerc√≠cios f√≠sicos para melhorar seu bem-estar f√≠sico e mental.
Suas recomenda√ß√µes devem ser baseadas em evid√™ncias cient√≠ficas e diretrizes de
sa√∫de (OMS, AHA, etc.).

Seja encorajador, positivo e pr√°tico. Pergunte sobre os h√°bitos atuais,
prefer√™ncias e barreiras do usu√°rio para oferecer sugest√µes personalizadas.
Explique os benef√≠cios cient√≠ficos do exerc√≠cio para a sa√∫de mental (redu√ß√£o de
ansiedade/depress√£o, melhora do humor).

Sugira come√ßar pequeno e aumentar gradualmente. Ofere√ßa diferentes tipos de
exerc√≠cio (caminhada, corrida, for√ßa, yoga) com base nas prefer√™ncias e
evid√™ncias.

Considere o hist√≥rico da conversa para lembrar de objetivos ou progressos
anteriores e personalize suas mensagens motivacionais.
"""

    def process_input(self, user_input: str, conversation_history: List[Dict[str, str]], user_profile: Dict[str, Any]) -> str:
        if not self.gemini_tool:
            return "Desculpe, o Agente de Exerc√≠cio n√£o est√° dispon√≠vel no momento."

        prompt = self._build_prompt(user_input, conversation_history, user_profile, self.instructions)
        return self.gemini_tool.generate_text(prompt)

class KnowledgeAgent(BaseAgent): # Corrigido: Herdar de BaseAgent
    """Agente especializado em fornecer informa√ß√µes baseadas em estudos e artigos cient√≠ficos."""
    def __init__(self, gemini_tool: Optional[GeminiTool]):
        super().__init__("AgenteConhecimento", "1.0.13", gemini_tool) # Vers√£o atualizada
        self.instructions = """
Voc√™ √© o AgenteConhecimento do BemEstarBot. Seu foco √© fornecer informa√ß√µes
precisas e baseadas em estudos e artigos cient√≠ficos sobre sa√∫de mental,
bem-estar e os benef√≠cios do exerc√≠cio.

Responda √†s perguntas do usu√°rio com informa√ß√µes claras, concisas e, quando
poss√≠vel, referencie (de forma conversacional) que a informa√ß√£o √© baseada em
evid√™ncias. Evite dar conselhos m√©dicos diretos.

Seja informativo e objetivo. Se uma pergunta estiver fora do seu escopo de
conhecimento cient√≠fico (por exemplo, "Como fa√ßo para cozinhar macarr√£o?"),
indique que voc√™ se concentra em sa√∫de e bem-estar baseados em evid√™ncias.

Considere o hist√≥rico da conversa para entender o contexto da pergunta por
informa√ß√£o.
"""

    def process_input(self, user_input: str, conversation_history: List[Dict[str, str]], user_profile: Dict[str, Any]) -> str:
        if not self.gemini_tool:
            return "Desculpe, o Agente de Conhecimento n√£o est√° dispon√≠vel no momento."

        prompt = self._build_prompt(user_input, conversation_history, user_profile, self.instructions)
        return self.gemini_tool.generate_text(prompt)

class MentorAgent(BaseAgent):
    """Agente especializado em atuar como mentor, motivador e acompanhador recorrente."""
    def __init__(self, gemini_tool: Optional[GeminiTool]):
        super().__init__("AgenteMentor", "1.0.10", gemini_tool) # Vers√£o atualizada
        self.instructions = """
Voc√™ √© o AgenteMentor do BemEstarBot. Seu papel √© ser um mentor, guia e motivador
constante para o usu√°rio em sua jornada de sa√∫de mental e bem-estar. Sua
comunica√ß√£o deve ser inspiradora, emp√°tica e focada no progresso a longo prazo.
Pense em um estilo de comunica√ß√£o que combine sabedoria, encorajamento e um toque
pessoal, como um mentor experiente.

Seja proativo no acompanhamento. Lembre o usu√°rio de seus objetivos, celebre
pequenas vit√≥rias e ofere√ßa suporte em momentos de dificuldade. Utilize o hist√≥rico
da conversa e o perfil do usu√°rio (se dispon√≠vel) para personalizar suas mensagens
e demonstrar que voc√™ se lembra do progresso e dos desafios anteriores.

Incentive a consist√™ncia nos exerc√≠cios e na aplica√ß√£o das t√©cnicas de sa√∫de mental.
Fa√ßa perguntas que levem √† reflex√£o sobre o progresso e os aprendizados.

Sua recorr√™ncia √© chave: em uma implementa√ß√£o completa, voc√™ iniciaria conversas
periodicamente para fazer check-ins e oferecer suporte cont√≠nuo. Nesta simula√ß√£o,
voc√™ responder√° quando o usu√°rio abordar t√≥picos relacionados a progresso,
motiva√ß√£o, objetivos ou acompanhamento.

Mantenha um tom caloroso, paciente e inspirador.
"""

    def process_input(self, user_input: str, conversation_history: List[Dict[str, str]], user_profile: Dict[str, Any]) -> str:
        if not self.gemini_tool:
            return "Desculpe, o Agente Mentor n√£o est√° dispon√≠vel no momento."

        prompt = self._build_prompt(user_input, conversation_history, user_profile, self.instructions)
        return self.gemini_tool.generate_text(prompt)


# --- Orquestrador ---

class Orchestrator:
    """
    Orquestrador que gerencia os agentes, ferramentas e o fluxo da conversa.
    Respons√°vel por rotear as entradas do usu√°rio para o agente apropriado.
    """
    def __init__(self, agents: Dict[str, BaseAgent]):
        self.agents = agents
        self.conversation_history: List[Dict[str, str]] = []
        self.user_profile: Dict[str, Any] = {} # Futuramente para armazenar dados do usu√°rio
        self.version = "1.0.13" # Vers√£o do Orquestrador atualizada

    def _log_conversation(self, sender: str, message: str) -> None:
        """
        Adiciona uma mensagem ao hist√≥rico da conversa.
        """
        # Limitar o tamanho do hist√≥rico para n√£o exceder o limite de tokens do modelo
        if len(self.conversation_history) > 100: # Aumentado o limite para m√∫ltiplos agentes
             self.conversation_history = self.conversation_history[-100:]

        self.conversation_history.append({"sender": sender, "content": message})

    def route_input_to_agent(self, user_input: str) -> str:
        """
        Direciona a entrada do usu√°rio para o agente apropriado com base em palavras-chave simples.
        Em uma implementa√ß√£o real, isso usaria PLN mais avan√ßado.

        Args:
            user_input (str): A mensagem do usu√°rio.

        Returns:
            str: O nome do agente selecionado para processar a entrada.
        """
        user_input_lower = user_input.lower()

        # L√≥gica de roteamento simples baseada em palavras-chave
        # Adicionando palavras-chave para o Agente Mentor
        if any(keyword in user_input_lower for keyword in ["mentor", "acompanhar", "motivar", "progresso", "objetivo", "meta", "como estou indo", "seguir em frente"]):
            agent_name = "AgenteMentor"
        elif any(keyword in user_input_lower for keyword in ["ansiedade", "depress√£o", "triste", "raiva", "pensamentos ruins", "sentindo", "emocional", "lidar com"]):
            agent_name = "AgenteSuporteEmocional"
        elif any(keyword in user_input_lower for keyword in ["exerc√≠cio", "atividade f√≠sica", "academia", "caminhada", "corrida", "malhar", "treino", "movimento", "ativo"]):
            agent_name = "AgenteExercicio"
        elif any(keyword in user_input_lower for keyword in ["estudo", "pesquisa", "cient√≠fico", "benef√≠cios", "informa√ß√£o", "evid√™ncia", "saber sobre", "o que √©"]):
             agent_name = "AgenteConhecimento"
        else:
            # Se nenhuma palavra-chave espec√≠fica for encontrada, direciona para o agente emocional como padr√£o
            # ou poderia ter um agente "Geral" ou "Sauda√ß√£o".
            agent_name = "AgenteSuporteEmocional" # Padr√£o para conversas gerais/emocionais

        return agent_name


    def process_user_input(self, user_input: str) -> str:
        """
        Recebe a entrada do usu√°rio, roteia para o agente apropriado e retorna a resposta.

        Args:
            user_input (str): A mensagem do usu√°rio.

        Returns:
            str: A resposta gerada pelo agente selecionado.
        """
        self._log_conversation("user", user_input) # Log antes de rotear

        # Roteia a entrada para o agente apropriado
        agent_name = self.route_input_to_agent(user_input)
        agent = self.agents.get(agent_name)

        if agent:
            print(f"(Orquestrador: Roteando para {agent.name})") # Para visualiza√ß√£o no console
            # Chama o m√©todo process_input do agente selecionado
            response = agent.process_input(user_input, self.conversation_history, self.user_profile)
        else:
            response = "Desculpe, n√£o consigo encontrar um agente adequado para lidar com isso."

        self._log_conversation("bot", response) # Log da resposta do bot
        return response


    def run(self) -> None:
        """Executa o loop principal do orquestrador."""
        # Verifica se a ferramenta Gemini foi inicializada com sucesso globalmente
        # Esta verifica√ß√£o foi movida para main() para melhor organiza√ß√£o
        # pass # Removemos a verifica√ß√£o duplicada aqui


        print(f"\nOrquestrador (vers√£o {self.version}) iniciado.")

        # Sauda√ß√£o inicial (tratada pelo orquestrador chamando um agente)
        # Pode ser o Agente Mentor ou Emocional para iniciar de forma acolhedora
        initial_greeting_agent = self.agents.get("AgenteMentor") # Usando o Mentor para a sauda√ß√£o inicial
        if initial_greeting_agent:
             initial_greeting = initial_greeting_agent.process_input("In√≠cio da conversa.", self.conversation_history, self.user_profile)
             self._log_conversation("bot", initial_greeting)
             print(f"BemEstarBot: {initial_greeting}")
        else:
             # Fallback caso o Agente Mentor n√£o esteja dispon√≠vel
             fallback_greeting_agent = self.agents.get("AgenteSuporteEmocional")
             if fallback_greeting_agent:
                  initial_greeting = fallback_greeting_agent.process_input("In√≠cio da conversa.", self.conversation_history, self.user_profile)
                  self._log_conversation("bot", initial_greeting)
                  print(f"BemEstarBot: {initial_greeting}")
             else:
                  print("BemEstarBot: Ol√°! Sou o BemEstarBot. No momento, estou com dificuldades para iniciar. Como posso te ajudar?")


        while True:
            user_input: str = input("Voc√™: ")
            if user_input.lower() == "sair":
                # Permite que um agente (ex: emocional ou mentor) gere uma despedida
                farewell_agent = self.agents.get("AgenteMentor") # Usando o Mentor para a despedida
                if farewell_agent:
                    farewell_response = farewell_agent.process_input("Usu√°rio deseja encerrar a conversa.", self.conversation_history, self.user_profile)
                    self._log_conversation("bot", farewell_response)
                    print(f"BemEstarBot: {farewell_response}")
                else:
                     # Fallback caso o Agente Mentor n√£o esteja dispon√≠vel
                    fallback_farewell_agent = self.agents.get("AgenteSuporteEmocional")
                    if fallback_farewell_agent:
                         farewell_response = fallback_farewell_agent.process_input("Usu√°rio deseja encerrar a conversa.", self.conversation_history, self.user_profile)
                         self._log_conversation("bot", farewell_response)
                         print(f"BemEstarBot: {farewell_response}")
                    else:
                         print("BemEstarBot: Tchau! Cuide-se!")
                break

            # O orquestrador processa a entrada do usu√°rio (roteia e obt√©m a resposta do agente)
            response: str = self.process_user_input(user_input)

            print(f"BemEstarBot: {response}")

            # Em uma aplica√ß√£o real, o orquestrador gerenciaria a persist√™ncia
            # do hist√≥rico da conversa e do perfil do usu√°rio ap√≥s cada intera√ß√£o.


def main() -> None:
    """
    Fun√ß√£o principal para configurar as ferramentas, agentes e iniciar o orquestrador.
    """
    # Verifica se a ferramenta Gemini foi inicializada com sucesso globalmente
    if gemini_tool is None:
         print("\nSistema de Agentes n√£o iniciado. A ferramenta Gemini n√£o foi configurada corretamente.")
         print("Por favor, verifique sua chave de API e a lista de modelos dispon√≠veis para sua conta.") # Mensagem aprimorada
         return

    # Inicializa os agentes, passando as ferramentas necess√°rias para cada um
    agents: Dict[str, BaseAgent] = {
        "AgenteSuporteEmocional": EmotionalSupportAgent(gemini_tool=gemini_tool),
        "AgenteExercicio": ExerciseAgent(gemini_tool=gemini_tool),
        "AgenteConhecimento": KnowledgeAgent(gemini_tool=gemini_tool),
        "AgenteMentor": MentorAgent(gemini_tool=gemini_tool), # Novo Agente Mentor adicionado
        # Adicionar outros agentes aqui no futuro
    }

    # Inicializa o Orquestrador com os agentes criados
    orchestrator = Orchestrator(agents=agents)

    # Inicia o loop de execu√ß√£o do orquestrador
    orchestrator.run()


if __name__ == "__main__":
    main()
